"""
Redis Cache Manager for RAG Passages
Professional-grade TWO-LEVEL caching layer with intelligent fallback

LEVEL 1: Intent + Chart Bucket Cache
- Key: intent_bucket + chart_bucket â†’ passage_ids + short_answer
- TTL: 6-24 hours (astrological rules are stable)
- Hit rate: 3-10x higher than full-prompt caching

LEVEL 2: Full Response Cache  
- Key: full_prompt_hash â†’ final_long_answer
- TTL: 1-6 hours (shorter, more specific)
- Backup for exact matches

Author: AI System Architect
"""

import json
import time
import hashlib
import logging
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime, timedelta

try:
    import redis
    from redis.exceptions import RedisError, ConnectionError as RedisConnectionError
    REDIS_AVAILABLE = True
except ImportError:
    REDIS_AVAILABLE = False
    logging.warning("Redis not installed. Using in-memory cache fallback.")

from niche_config import CACHE_CONFIG, get_cache_ttl

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class CacheManager:
    """
    Professional-grade TWO-LEVEL cache manager with Redis + in-memory fallback
    
    LEVEL 1: Intent + Chart Bucket Cache (hot intent cache)
    - Stores: intent_bucket + chart_bucket â†’ top_passage_ids + draft_answer
    - Use case: Many similar questions ("When will I meet spouse?") with similar charts
    - Hit rate: 3-10x higher than full-prompt caching
    - TTL: 6-24 hours (astrological rules stable)
    
    LEVEL 2: Full Response Cache (full prompt cache)
    - Stores: full_prompt_hash â†’ final_long_answer
    - Use case: Exact same question + same chart
    - Hit rate: Lower, but perfect accuracy
    - TTL: 1-6 hours (shorter, more specific)
    
    Features:
    - Redis primary cache
    - In-memory fallback if Redis unavailable
    - Automatic TTL management
    - Cache hit/miss tracking
    - Batch operations
    - Thread-safe operations
    """
    
    def __init__(self, use_redis: bool = True):
        """
        Initialize TWO-LEVEL cache manager
        
        Args:
            use_redis: Whether to use Redis (falls back to memory if unavailable)
        """
        self.use_redis = use_redis and REDIS_AVAILABLE and CACHE_CONFIG.get("enabled", True)
        self.redis_client = None
        self.memory_cache: Dict[str, Dict[str, Any]] = {}
        
        # Separate stats for each cache level
        self.cache_stats = {
            "level1_hits": 0,      # Intent bucket hits
            "level1_misses": 0,
            "level2_hits": 0,      # Full prompt hits
            "level2_misses": 0,
            "sets": 0,
            "errors": 0,
            "time_saved_ms": 0,
        }
        
        if self.use_redis:
            self._initialize_redis()
        else:
            logger.info("Using in-memory cache (Redis disabled or unavailable)")
    
    def _initialize_redis(self):
        """Initialize Redis connection with error handling"""
        try:
            redis_config = CACHE_CONFIG.get("redis", {})
            
            self.redis_client = redis.Redis(
                host=redis_config.get("host", "localhost"),
                port=redis_config.get("port", 6379),
                db=redis_config.get("db", 0),
                password=redis_config.get("password"),
                socket_timeout=redis_config.get("socket_timeout", 5),
                socket_connect_timeout=redis_config.get("socket_connect_timeout", 5),
                decode_responses=redis_config.get("decode_responses", True),
            )
            
            # Test connection
            self.redis_client.ping()
            logger.info("âœ… Redis cache initialized successfully")
            
        except Exception as e:
            logger.warning(f"âš ï¸ Redis connection failed: {e}. Falling back to memory cache.")
            self.redis_client = None
            self.use_redis = False
    
    def get_level1(
        self,
        intent_bucket: str,
        chart_bucket: str
    ) -> Optional[Dict[str, Any]]:
        """
        LEVEL 1: Get from intent+chart bucket cache
        
        Returns cached passage IDs and draft answer for similar queries
        
        Args:
            intent_bucket: Intent classification (e.g., "timing_marriage")
            chart_bucket: Chart fingerprint bucket (e.g., "venus_7th_saturn_strong")
        
        Returns:
            Dict with:
                - passage_ids: List of top passage IDs
                - draft_answer: Short cached answer
                - timestamp: Cache creation time
            Or None if not found
        """
        key = self._build_level1_key(intent_bucket, chart_bucket)
        
        try:
            if self.use_redis and self.redis_client:
                value = self.redis_client.get(key)
                if value:
                    self.cache_stats["level1_hits"] += 1
                    data = json.loads(value)
                    logger.debug(f"  âœ… Level 1 cache hit: {intent_bucket} + {chart_bucket}")
                    return data
                else:
                    self.cache_stats["level1_misses"] += 1
                    return None
            else:
                cached = self.memory_cache.get(key)
                if cached and cached["expires_at"] > time.time():
                    self.cache_stats["level1_hits"] += 1
                    return cached["value"]
                elif cached:
                    del self.memory_cache[key]
                
                self.cache_stats["level1_misses"] += 1
                return None
                
        except Exception as e:
            logger.error(f"Level 1 cache get error: {e}")
            self.cache_stats["errors"] += 1
            return None
    
    def set_level1(
        self,
        intent_bucket: str,
        chart_bucket: str,
        passage_ids: List[str],
        draft_answer: str,
        ttl_hours: int = 12
    ):
        """
        LEVEL 1: Set intent+chart bucket cache
        
        Args:
            intent_bucket: Intent classification
            chart_bucket: Chart fingerprint
            passage_ids: Top passage IDs for this intent+chart combo
            draft_answer: Short draft answer
            ttl_hours: Time to live in hours (default: 12)
        """
        key = self._build_level1_key(intent_bucket, chart_bucket)
        
        data = {
            "passage_ids": passage_ids,
            "draft_answer": draft_answer,
            "timestamp": time.time(),
        }
        
        ttl_seconds = ttl_hours * 3600
        
        try:
            if self.use_redis and self.redis_client:
                self.redis_client.setex(key, ttl_seconds, json.dumps(data))
            else:
                self.memory_cache[key] = {
                    "value": data,
                    "expires_at": time.time() + ttl_seconds,
                    "created_at": time.time()
                }
            
            self.cache_stats["sets"] += 1
            logger.debug(f"  ðŸ’¾ Level 1 cache set: {intent_bucket} + {chart_bucket}")
            
        except Exception as e:
            logger.error(f"Level 1 cache set error: {e}")
            self.cache_stats["errors"] += 1
    
    def get_level2(self, prompt_hash: str) -> Optional[str]:
        """
        LEVEL 2: Get from full prompt cache
        
        Returns exact cached response for full prompt
        
        Args:
            prompt_hash: Hash of full prompt
        
        Returns:
            Full cached response or None
        """
        key = self._build_level2_key(prompt_hash)
        
        try:
            if self.use_redis and self.redis_client:
                value = self.redis_client.get(key)
                if value:
                    self.cache_stats["level2_hits"] += 1
                    logger.debug(f"  âœ… Level 2 cache hit: {prompt_hash[:16]}")
                    return json.loads(value)
                else:
                    self.cache_stats["level2_misses"] += 1
                    return None
            else:
                cached = self.memory_cache.get(key)
                if cached and cached["expires_at"] > time.time():
                    self.cache_stats["level2_hits"] += 1
                    return cached["value"]
                elif cached:
                    del self.memory_cache[key]
                
                self.cache_stats["level2_misses"] += 1
                return None
                
        except Exception as e:
            logger.error(f"Level 2 cache get error: {e}")
            self.cache_stats["errors"] += 1
            return None
    
    def set_level2(
        self,
        prompt_hash: str,
        response: str,
        ttl_hours: int = 3
    ):
        """
        LEVEL 2: Set full prompt cache
        
        Args:
            prompt_hash: Hash of full prompt
            response: Full response text
            ttl_hours: Time to live in hours (default: 3, shorter than L1)
        """
        key = self._build_level2_key(prompt_hash)
        ttl_seconds = ttl_hours * 3600
        
        try:
            if self.use_redis and self.redis_client:
                self.redis_client.setex(key, ttl_seconds, json.dumps(response))
            else:
                self.memory_cache[key] = {
                    "value": response,
                    "expires_at": time.time() + ttl_seconds,
                    "created_at": time.time()
                }
            
            self.cache_stats["sets"] += 1
            logger.debug(f"  ðŸ’¾ Level 2 cache set: {prompt_hash[:16]}")
            
        except Exception as e:
            logger.error(f"Level 2 cache set error: {e}")
            self.cache_stats["errors"] += 1
    
    def _build_level1_key(self, intent_bucket: str, chart_bucket: str) -> str:
        """Build Level 1 cache key"""
        return f"astro:l1:{intent_bucket}:{chart_bucket}"
    
    def _build_level2_key(self, prompt_hash: str) -> str:
        """Build Level 2 cache key"""
        return f"astro:l2:{prompt_hash}"
    
    def compute_intent_bucket(self, question: str, niche: str) -> str:
        """
        Compute intent bucket from question
        
        Buckets similar questions together for cache reuse
        
        Args:
            question: User's question
            niche: Astrology niche
        
        Returns:
            Intent bucket string (e.g., "timing_marriage_love")
        """
        q_lower = question.lower()
        
        # Timing questions
        if any(w in q_lower for w in ["when", "timing", "date", "period"]):
            if "marriage" in q_lower or "spouse" in q_lower:
                return f"timing_marriage_{niche.lower().replace(' ', '_')}"
            elif "job" in q_lower or "career" in q_lower:
                return f"timing_career_{niche.lower().replace(' ', '_')}"
            else:
                return f"timing_general_{niche.lower().replace(' ', '_')}"
        
        # Appearance questions
        elif any(w in q_lower for w in ["look", "appear", "beautiful", "handsome"]):
            return f"appearance_spouse_{niche.lower().replace(' ', '_')}"
        
        # Personality questions
        elif any(w in q_lower for w in ["personality", "nature", "like", "character"]):
            return f"personality_spouse_{niche.lower().replace(' ', '_')}"
        
        # Location questions
        elif "where" in q_lower or "meet" in q_lower:
            return f"location_meeting_{niche.lower().replace(' ', '_')}"
        
        # General niche questions
        else:
            return f"general_{niche.lower().replace(' ', '_')}"
    
    def compute_chart_bucket(self, chart_factors: Dict[str, Any]) -> str:
        """
        Compute chart bucket fingerprint
        
        Groups similar charts together (same key placements)
        
        Args:
            chart_factors: Chart factor dict
        
        Returns:
            Chart bucket string (e.g., "venus_7th_saturn_strong")
        """
        # Extract key factors for bucketing
        key_factors = []
        
        # 7th house factors (marriage)
        if chart_factors.get("7th_lord"):
            key_factors.append(f"7lord_{chart_factors['7th_lord']}")
        if chart_factors.get("venus_sign"):
            key_factors.append(f"venus_{chart_factors['venus_sign']}")
        if chart_factors.get("saturn_sign"):
            key_factors.append(f"saturn_{chart_factors['saturn_sign']}")
        
        # Dasha
        if chart_factors.get("current_mahadasha"):
            key_factors.append(f"dasha_{chart_factors['current_mahadasha']}")
        
        # Create bucket hash
        bucket_str = "_".join(key_factors[:5])  # Max 5 factors
        
        # Hash to keep bucket names short
        bucket_hash = hashlib.md5(bucket_str.encode()).hexdigest()[:12]
        
        return bucket_hash
        """
        Get value from cache
        
        Args:
            key: Cache key
        
        Returns:
            Cached value or None if not found
        """
        try:
            if self.use_redis and self.redis_client:
                # Try Redis first
                value = self.redis_client.get(key)
                if value:
                    self.cache_stats["hits"] += 1
                    return json.loads(value)
                else:
                    self.cache_stats["misses"] += 1
                    return None
            else:
                # Use memory cache
                cached = self.memory_cache.get(key)
                if cached and cached["expires_at"] > time.time():
                    self.cache_stats["hits"] += 1
                    return cached["value"]
                elif cached:
                    # Expired - remove it
                    del self.memory_cache[key]
                
                self.cache_stats["misses"] += 1
                return None
                
        except Exception as e:
            logger.error(f"Cache get error for key {key}: {e}")
            self.cache_stats["errors"] += 1
            return None
    
    def set(self, key: str, value: Any, ttl_seconds: Optional[int] = None):
        """
        Set value in cache with TTL
        
        Args:
            key: Cache key
            value: Value to cache (will be JSON serialized)
            ttl_seconds: Time to live in seconds (None = default)
        """
        try:
            if ttl_seconds is None:
                ttl_seconds = CACHE_CONFIG.get("default_ttl_minutes", 60) * 60
            
            if self.use_redis and self.redis_client:
                # Store in Redis
                self.redis_client.setex(
                    key,
                    ttl_seconds,
                    json.dumps(value)
                )
            else:
                # Store in memory
                self.memory_cache[key] = {
                    "value": value,
                    "expires_at": time.time() + ttl_seconds,
                    "created_at": time.time()
                }
            
            self.cache_stats["sets"] += 1
            
        except Exception as e:
            logger.error(f"Cache set error for key {key}: {e}")
            self.cache_stats["errors"] += 1
    
    def delete(self, key: str):
        """Delete key from cache"""
        try:
            if self.use_redis and self.redis_client:
                self.redis_client.delete(key)
            else:
                self.memory_cache.pop(key, None)
        except Exception as e:
            logger.error(f"Cache delete error for key {key}: {e}")
    
    def exists(self, key: str) -> bool:
        """Check if key exists in cache"""
        try:
            if self.use_redis and self.redis_client:
                return self.redis_client.exists(key) > 0
            else:
                cached = self.memory_cache.get(key)
                return cached is not None and cached["expires_at"] > time.time()
        except Exception as e:
            logger.error(f"Cache exists error for key {key}: {e}")
            return False
    
    def get_many(self, keys: List[str]) -> Dict[str, Any]:
        """
        Get multiple keys at once (batch operation)
        
        Args:
            keys: List of cache keys
        
        Returns:
            Dict mapping keys to values (missing keys not included)
        """
        results = {}
        
        if self.use_redis and self.redis_client:
            try:
                # Use Redis pipeline for efficiency
                pipe = self.redis_client.pipeline()
                for key in keys:
                    pipe.get(key)
                
                values = pipe.execute()
                
                for key, value in zip(keys, values):
                    if value:
                        results[key] = json.loads(value)
                        self.cache_stats["hits"] += 1
                    else:
                        self.cache_stats["misses"] += 1
                        
            except Exception as e:
                logger.error(f"Batch get error: {e}")
                # Fall back to individual gets
                for key in keys:
                    value = self.get(key)
                    if value:
                        results[key] = value
        else:
            # Memory cache - iterate
            for key in keys:
                value = self.get(key)
                if value:
                    results[key] = value
        
        return results
    
    def set_many(self, items: Dict[str, Any], ttl_seconds: Optional[int] = None):
        """
        Set multiple keys at once (batch operation)
        
        Args:
            items: Dict mapping keys to values
            ttl_seconds: TTL for all keys
        """
        if ttl_seconds is None:
            ttl_seconds = CACHE_CONFIG.get("default_ttl_minutes", 60) * 60
        
        if self.use_redis and self.redis_client:
            try:
                # Use Redis pipeline
                pipe = self.redis_client.pipeline()
                for key, value in items.items():
                    pipe.setex(key, ttl_seconds, json.dumps(value))
                pipe.execute()
                
                self.cache_stats["sets"] += len(items)
                
            except Exception as e:
                logger.error(f"Batch set error: {e}")
                # Fall back to individual sets
                for key, value in items.items():
                    self.set(key, value, ttl_seconds)
        else:
            # Memory cache - iterate
            for key, value in items.items():
                self.set(key, value, ttl_seconds)
    
    def clear_session(self, session_id: str):
        """
        Clear all cache entries for a session
        
        Args:
            session_id: Session identifier
        """
        try:
            if self.use_redis and self.redis_client:
                # Find all keys matching session pattern
                pattern = f"astro:rag:{session_id}:*"
                keys = self.redis_client.keys(pattern)
                
                if keys:
                    self.redis_client.delete(*keys)
                    logger.info(f"Cleared {len(keys)} cache entries for session {session_id}")
            else:
                # Memory cache - filter by session
                keys_to_delete = [
                    k for k in self.memory_cache.keys()
                    if f":{session_id}:" in k
                ]
                for key in keys_to_delete:
                    del self.memory_cache[key]
                
                logger.info(f"Cleared {len(keys_to_delete)} cache entries for session {session_id}")
                
        except Exception as e:
            logger.error(f"Clear session error: {e}")
    
    def get_stats(self) -> Dict[str, Any]:
        """
        Get cache statistics
        
        Returns:
            Dict with hit/miss rates, counts, etc.
        """
        total_requests = self.cache_stats["hits"] + self.cache_stats["misses"]
        hit_rate = (
            self.cache_stats["hits"] / total_requests
            if total_requests > 0
            else 0.0
        )
        
        stats = {
            **self.cache_stats,
            "total_requests": total_requests,
            "hit_rate": hit_rate,
            "cache_type": "redis" if self.use_redis else "memory",
            "memory_cache_size": len(self.memory_cache),
        }
        
        if self.use_redis and self.redis_client:
            try:
                info = self.redis_client.info()
                stats["redis_keys"] = info.get("db0", {}).get("keys", 0)
                stats["redis_memory"] = info.get("used_memory_human", "N/A")
            except:
                pass
        
        return stats
    
    def health_check(self) -> Dict[str, Any]:
        """
        Check cache health status
        
        Returns:
            Health status dict
        """
        status = {
            "healthy": True,
            "cache_type": "redis" if self.use_redis else "memory",
            "timestamp": datetime.utcnow().isoformat()
        }
        
        if self.use_redis and self.redis_client:
            try:
                self.redis_client.ping()
                status["redis_connected"] = True
            except Exception as e:
                status["healthy"] = False
                status["redis_connected"] = False
                status["error"] = str(e)
        
        return status
    
    def cleanup_expired(self):
        """Clean up expired entries (for memory cache)"""
        if not self.use_redis:
            current_time = time.time()
            expired_keys = [
                key for key, data in self.memory_cache.items()
                if data["expires_at"] <= current_time
            ]
            
            for key in expired_keys:
                del self.memory_cache[key]
            
            if expired_keys:
                logger.info(f"Cleaned up {len(expired_keys)} expired cache entries")


# Global cache instance
_cache_manager: Optional[CacheManager] = None


def get_cache_manager() -> CacheManager:
    """
    Get global cache manager instance (singleton pattern)
    
    Returns:
        CacheManager instance
    """
    global _cache_manager
    
    if _cache_manager is None:
        _cache_manager = CacheManager()
    
    return _cache_manager


def build_cache_key(session_id: str, niche: str, factor: str) -> str:
    """
    Build standardized cache key
    
    Args:
        session_id: Session identifier
        niche: Astrology niche
        factor: Chart factor name
    
    Returns:
        Cache key string
    """
    # Normalize inputs
    niche_normalized = niche.lower().replace(" ", "_").replace("&", "and")
    factor_normalized = factor.lower().replace(" ", "_")
    
    return f"astro:rag:{session_id}:{niche_normalized}:{factor_normalized}"
